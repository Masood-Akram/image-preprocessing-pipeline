{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d852ee58",
   "metadata": {},
   "source": [
    "## load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d010ffc4",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T06:09:58.737418Z",
     "start_time": "2024-03-12T06:09:56.636635300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m display, HTML\n\u001B[0;32m      2\u001B[0m display(HTML(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<style>.container \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m width:100\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m !important; }</style>\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprocess_images\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpystripe\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\image-preprocessing-pipeline\\process_images.py:34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfilters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sobel\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfilters\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthresholding\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m threshold_multiotsu\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuda\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_per_process_memory_fraction \u001B[38;5;28;01mas\u001B[39;00m cuda_set_per_process_memory_fraction\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_flat_img\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mparallel_image_processor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parallel_image_processor, jumpy_step_range\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from process_images import *\n",
    "from pystripe.core import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(img_list: List[ndarray], img_labels: List[str], vmax: int):\n",
    "    if len(img_list) == 1:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(img_list[0], cmap='gray', vmin=0, vmax=vmax)\n",
    "        plt.title(img_labels[0])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=len(img_list), figsize=(20, 20))\n",
    "        for idx, (im, label) in enumerate(zip(img_list, img_labels)):\n",
    "            axes[idx].imshow(im, cmap='gray', vmin=0, vmax=vmax)\n",
    "            axes[idx].set_title(label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_image_processor import *\n",
    "tsv_volume = TSVVolume.load(r'E:\\20230510_13_34_13_SM230308_05_LS_15x_800z_MIP_stitched\\Ex_488_Em_525_MIP_xml_import_step_5.xml')\n",
    "shape: Tuple[int, int, int] = tsv_volume.volume.shape  # shape is in z y x format\n",
    "img = tsv_volume.imread(\n",
    "    VExtent(\n",
    "        tsv_volume.volume.x0, tsv_volume.volume.x1,\n",
    "        tsv_volume.volume.y0, tsv_volume.volume.y1,\n",
    "        tsv_volume.volume.z0 + shape[0]//2, tsv_volume.volume.z0 + shape[0]//2 + 1),\n",
    "    tsv_volume.dtype)[0]\n",
    "parallel_image_processor(\n",
    "    source=TSVVolume.load(r'/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_xml_import_step_5.xml'),\n",
    "    destination=r\"/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_tif\",\n",
    "    fun=process_img,\n",
    "    kwargs={'bleach_correction_frequency': 0.0005, 'bleach_correction_max_method': False, 'bleach_correction_y_slice_max': None, 'threshold': None, 'sigma': (4000.0, 4000.0), 'bidirectional': True, 'lightsheet': False, 'percentile': 0.25, 'rotate': 90, 'convert_to_8bit': False, 'bit_shift_to_right': 8, 'tile_size': (39220, 28056), 'd_type': 'uint16', \"verbose\": True},\n",
    "    source_voxel=(0.8, 0.4, 0.4),\n",
    "    target_voxel=20,\n",
    "    max_processors=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_layer(\n",
    "    index: int,          # layer of image requested\n",
    "    image: ndarray,      # 3-D image (use TifStack.as_3d_numpy())\n",
    "    plane = \"xy\",        # must be \"xy\", \"yx\", \"xz\", \"zx\", \"yz\", \"zy\"\n",
    "    img_format = \"zyx\",  # xyz in some order\n",
    "):\n",
    "    # guards\n",
    "    if plane not in {\"xy\", \"yx\", \"xz\", \"zx\", \"yz\", \"zy\"} or img_format not in {\"zyx\", \"zxy\", \"yxz\", \"yzx\", \"xyz\", \"xzy\"}:\n",
    "        print(f\"Invalid plane selected in get_layer().  Plane: {plane}, Layer: {index}, Img_format: {img_format}\\nReturning to caller...\")\n",
    "        return None\n",
    "\n",
    "    # get the layer\n",
    "    if 'x' not in plane:   sub = img_format.index('x')\n",
    "    elif 'y' not in plane: sub = img_format.index('y')\n",
    "    elif 'z' not in plane: sub = img_format.index('z')\n",
    "\n",
    "    if sub == 0:   layer_image = image[index, :, :]\n",
    "    elif sub == 1: layer_image = image[:, index, :]\n",
    "    elif sub == 2: layer_image = image[:, :, index]\n",
    "\n",
    "    # if plane is flipped compared to image format, return the transpose.\n",
    "    if plane not in (img_format[:sub] + img_format[sub + 1:]):\n",
    "        return layer_image.transpose()\n",
    "    return layer_image\n",
    "\n",
    "# run to rotate images\n",
    "from os import makedirs\n",
    "\n",
    "######## CHANGE THESE ########\n",
    "cha1_path = \"D:/BMAP/Brain 4/cha1\"\n",
    "cha2_path = \"D:/BMAP/Brain 4/cha2\"\n",
    "cha3_path = \"D:/BMAP/Brain 4/cha3\"\n",
    "# set to None if nothing to convert\n",
    "\n",
    "##############################\n",
    "if cha1_path:\n",
    "    makedirs(cha1_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha1_path + \"_zy\", exist_ok=True)\n",
    "    stack1 = TifStack(cha1_path).as_3d_numpy()\n",
    "    for i in range(stack1.shape[1]):\n",
    "        imwrite(cha1_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack1, \"zx\"))\n",
    "    for i in range(stack1.shape[2]):\n",
    "        imwrite(cha1_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack1, \"zy\"))\n",
    "if cha2_path:\n",
    "    makedirs(cha2_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha2_path + \"_zy\", exist_ok=True)\n",
    "    stack2 = TifStack(cha2_path).as_3d_numpy()\n",
    "    for i in range(stack2.shape[1]):\n",
    "        imwrite(cha2_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack2, \"zx\"))\n",
    "    for i in range(stack2.shape[2]):\n",
    "        imwrite(cha2_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack2, \"zy\"))\n",
    "if cha3_path:\n",
    "    makedirs(cha3_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha3_path + \"_zy\", exist_ok=True)\n",
    "    stack3 = TifStack(cha3_path).as_3d_numpy()\n",
    "    for i in range(stack3.shape[1]):\n",
    "        imwrite(cha3_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack3, \"zx\"))\n",
    "    for i in range(stack3.shape[2]):\n",
    "        imwrite(cha3_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack3, \"zy\"))\n",
    "print(\"Operation Completed\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_data(file_path:str, title:str, label1:str, label2:str):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        line = file.readline()\n",
    "\n",
    "        x_offset = [0]\n",
    "        y_offset = [0]\n",
    "\n",
    "        while line:\n",
    "            if \"Skipped\" in line:\n",
    "                x_offset.append(0)\n",
    "                y_offset.append(0)\n",
    "                line = file.readline()\n",
    "                continue\n",
    "            s = line.split(\",\")\n",
    "            x_offset.append(float(s[-2][:-1]))\n",
    "            line = file.readline()\n",
    "            s = line.split(\",\")\n",
    "            y_offset.append(float(s[-2][:-1]))\n",
    "            line = file.readline()\n",
    "            # skip last line\n",
    "            line = file.readline()\n",
    "\n",
    "        plt.plot(range(len(x_offset)), x_offset, label=label1)\n",
    "        plt.plot(range(len(y_offset)), y_offset, label=label2)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Layer index\")\n",
    "        plt.ylabel(\"Units\")\n",
    "        plt.ylim((-20, 20))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zy_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from zy-slices\", \"z-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zy_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from zy-slices\", \"z-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zx_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from zx-slices\", \"z-offset\", \"x-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zx_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from zx-slices\", \"z-offset\", \"x-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/xy_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from xy-slices\", \"x-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/xy_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from xy-slices\", \"x-offset\", \"y-offset\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ndarray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrite_to_file\u001B[39m(images: \u001B[38;5;28mlist\u001B[39m[\u001B[43mndarray\u001B[49m], filepath: Path):\n\u001B[0;32m      3\u001B[0m     filepath\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m     cha_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ndarray' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def write_to_file(images: list[ndarray], filepath: Path):\n",
    "    filepath.mkdir(parents=True, exist_ok=True)\n",
    "    cha_num = 0\n",
    "    for image in images:\n",
    "        local = filepath.parent / f'cha{cha_num}'\n",
    "        local.mkdir(parents=True, exist_ok=True)\n",
    "        for layer in range(image.shape[0]):\n",
    "            imwrite(local.absolute() + \"/\" + str(layer + 1) + \".tif\", get_layer(i, stack1, \"xy\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T06:10:27.500260700Z",
     "start_time": "2024-03-12T06:10:27.435939800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malign_images\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m align_all_images, resize_arrays\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msupplements\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtifstack\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TifStack\n\u001B[0;32m      4\u001B[0m cha1 \u001B[38;5;241m=\u001B[39m TifStack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:/Users/adnja/Documents/GitHub/image-preprocessing-pipeline/tempData/cha1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mas_3d_numpy()\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\image-preprocessing-pipeline\\align_images.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ndarray, zeros, pad, copy\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pool\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprocess_images\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_gradient, get_transformation_matrix\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# pads arr with zeroes evenly (as possible) on all sides to match pad_shape\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpad_to_shape\u001B[39m(pad_shape: \u001B[38;5;28mtuple\u001B[39m, arr: ndarray):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\image-preprocessing-pipeline\\process_images.py:34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfilters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sobel\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfilters\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mthresholding\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m threshold_multiotsu\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuda\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_per_process_memory_fraction \u001B[38;5;28;01mas\u001B[39;00m cuda_set_per_process_memory_fraction\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_flat_img\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mparallel_image_processor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parallel_image_processor, jumpy_step_range\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from align_images import align_all_images, resize_arrays\n",
    "from supplements.tifstack import TifStack\n",
    "\n",
    "cha1 = TifStack(\"C:/Users/adnja/Documents/GitHub/image-preprocessing-pipeline/tempData/cha1\").as_3d_numpy()\n",
    "cha2 = TifStack(\"C:/Users/adnja/Documents/GitHub/image-preprocessing-pipeline/tempData/cha2\").as_3d_numpy()\n",
    "cha3 = TifStack(\"C:/Users/adnja/Documents/GitHub/image-preprocessing-pipeline/tempData/cha3\").as_3d_numpy()\n",
    "max_iterations = 50\n",
    "\n",
    "channels = resize_arrays([cha1, cha2, cha3])\n",
    "print(\"test\")\n",
    "for i in channels:\n",
    "    print(i.shape)\n",
    "alignments, residuals = align_all_images(channels, verbose=True, make_copy=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Alignment: \", end='')\n",
    "print(alignments)\n",
    "print(\"Residuals: \", end='')\n",
    "print(residuals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T06:10:21.608424400Z",
     "start_time": "2024-03-12T06:10:21.348423800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "* make align_images make copy\n",
    "* function that takes in array of stacks and returns array of offsets\n",
    "    * choose reference image\n",
    "\n",
    "* submit refactored code\n",
    "\n",
    "* try using mask for better edge detection\n",
    "* Sobel operator -> mask -> align"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cha1 = TifStack(\"C:/Users/adnja/Documents/GitHub/image-preprocessing-pipeline/tempData/cha1\").as_3d_numpy()\n",
    "\n",
    "path = Path(\"E:/quick_write_testing\")\n",
    "\n",
    "write_to_file([cha1], path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
