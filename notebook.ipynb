{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d852ee58",
   "metadata": {},
   "source": [
    "## load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d010ffc4",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:22:47.743749300Z",
     "start_time": "2023-08-15T08:22:44.344986500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cpufeature as cpufeature\n",
    "import dcimg as dcimg\n",
    "import numba as numba\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from process_images import *\n",
    "from pystripe.core import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(img_list: List[ndarray], img_labels: List[str], vmax: int):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(img_list), figsize=(20, 20))\n",
    "    for idx, (im, label) in enumerate(zip(img_list, img_labels)):\n",
    "        axes[idx].imshow(im, cmap='gray', vmin=0, vmax=vmax)\n",
    "        axes[idx].set_title(label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_image_processor import *\n",
    "tsv_volume = TSVVolume.load(r'E:\\20230510_13_34_13_SM230308_05_LS_15x_800z_MIP_stitched\\Ex_488_Em_525_MIP_xml_import_step_5.xml')\n",
    "shape: Tuple[int, int, int] = tsv_volume.volume.shape  # shape is in z y x format\n",
    "img = tsv_volume.imread(\n",
    "    VExtent(\n",
    "        tsv_volume.volume.x0, tsv_volume.volume.x1,\n",
    "        tsv_volume.volume.y0, tsv_volume.volume.y1,\n",
    "        tsv_volume.volume.z0 + shape[0]//2, tsv_volume.volume.z0 + shape[0]//2 + 1),\n",
    "    tsv_volume.dtype)[0]\n",
    "parallel_image_processor(\n",
    "    source=TSVVolume.load(r'/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_xml_import_step_5.xml'),\n",
    "    destination=r\"/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_tif\",\n",
    "    fun=process_img,\n",
    "    kwargs={'bleach_correction_frequency': 0.0005, 'bleach_correction_max_method': False, 'bleach_correction_y_slice_max': None, 'threshold': None, 'sigma': (4000.0, 4000.0), 'bidirectional': True, 'lightsheet': False, 'percentile': 0.25, 'rotate': 90, 'convert_to_8bit': False, 'bit_shift_to_right': 8, 'tile_size': (39220, 28056), 'd_type': 'uint16', \"verbose\": True},\n",
    "    source_voxel=(0.8, 0.4, 0.4),\n",
    "    target_voxel=20,\n",
    "    max_processors=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from filestack import FileStack\n",
    "\n",
    "# 0 < percentile < 100\n",
    "def get_matrix_two_images(image1, image2, percentile):\n",
    "    # there should never be a case where both images are none, but this function checks just in case.\n",
    "    if image1 is None and image2 is None: return None\n",
    "\n",
    "    # check image1 type\n",
    "    if not isinstance(image1, ndarray) and not image1 is None:\n",
    "        #normally we need to convert the .tif file to be gray, but these tif files are already single-channel.\n",
    "        img1 = cv2.imread(image1, flags=cv2.IMREAD_ANYDEPTH)\n",
    "    elif image1 is None: return image2\n",
    "    else: img1 = image1\n",
    "\n",
    "    # check image2 type\n",
    "    if not isinstance(image2, ndarray) and not image2 is None:\n",
    "        img2 = cv2.imread(image2, flags=cv2.IMREAD_ANYDEPTH)\n",
    "    elif image2 is None: return image1\n",
    "    else: img2 = image2\n",
    "\n",
    "    # generate matrices\n",
    "    img1_percentile = np.percentile(img1, percentile)\n",
    "    img2_percentile = np.percentile(img2, percentile)\n",
    "\n",
    "    # scale images to max brightness at percentile; 0 <= pixel intensity <= 1\n",
    "    for i in range(len(img1)):\n",
    "        for j in range(len(img1[0])):\n",
    "            if img1[i][j] > img1_percentile:\n",
    "                img1[i][j] = img1_percentile\n",
    "            img1[i][j] *= (1 / img1_percentile)\n",
    "    for i in range(len(img2)):\n",
    "        for j in range(len(img2[0])):\n",
    "            if img2[i][j] > img2_percentile:\n",
    "                img2[i][j] = img2_percentile\n",
    "            img2[i][j] *= (1 / img2_percentile)\n",
    "\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "    num_iter = 10000\n",
    "    termination_eps = 1e-10\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, num_iter, termination_eps)\n",
    "\n",
    "    cc, warp_matrix = cv2.findTransformECC(img1, img2, warp_matrix, warp_mode, criteria)\n",
    "    return warp_matrix\n",
    "\n",
    "def generate_combined_image(images, matrices):\n",
    "    # there should always be 1 more image than number of matrices.  Example: 3 images, 2 matrices.\n",
    "    if len(images) != len(matrices) + 1:\n",
    "        raise Exception(\"Images and matrices arrays have incorrect lengths\")\n",
    "    img0 = cv2.imread(str(images[0].absolute()), flags=cv2.IMREAD_ANYDEPTH)\n",
    "    size = img0.shape\n",
    "    transformed_images = [img0]\n",
    "    for i in range(1, len(images)):\n",
    "        if not images[i] is None:\n",
    "            read_img = cv2.imread(str(images[i].absolute()), flags=cv2.IMREAD_ANYDEPTH)\n",
    "        else:\n",
    "            read_img = np.zeros(size, dtype = img0.dtype)\n",
    "\n",
    "        warped_image = cv2.warpAffine(read_img, matrices[i - 1], (size[1], size[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        transformed_images.append(warped_image)\n",
    "\n",
    "\n",
    "    merged = cv2.merge(transformed_images)\n",
    "\n",
    "    # for testing purposes\n",
    "    # cv2.imshow(\"Image 0\", transformed_images[0])\n",
    "    # cv2.imshow(\"Image 1\", transformed_images[1])\n",
    "    # cv2.imshow(\"Image 2\", transformed_images[2])\n",
    "    # cv2.imshow(\"Merged\", merged)\n",
    "    # cv2.waitKey(0)\n",
    "    return merged\n",
    "\n",
    "def merge_channels(paths, output):\n",
    "    print(\"Merging\")\n",
    "    stacks = []\n",
    "    for i in paths:\n",
    "        stacks.append(FileStack(i))\n",
    "    largest_stack_index = max([i.get_count() for i in stacks])\n",
    "\n",
    "    # generates a matrix using middle images of each stack, then apply it to all images in the stacks\n",
    "    # should not be parallelized; this is only done once.\n",
    "    ind = list(map(lambda x: x.get_count() // 2, stacks))\n",
    "    percentile = 90\n",
    "    matrices = list(map(lambda p: get_matrix_two_images(str(stacks[0].get_index(ind[0]).absolute()), p, percentile), [str(stacks[i].get_index(ind[i]).absolute()) for i in range(1, len(stacks))]))\n",
    "\n",
    "    # apply transformations to every image\n",
    "    # loop can be replaced with stack and multiple threads\n",
    "    for i in range(largest_stack_index):\n",
    "        filename = str(output.absolute() / 'merged_') + str(i) + \".tif\"\n",
    "        imsave_tif(filename, generate_combined_image([j.get_index(i) for j in stacks], matrices))\n",
    "\n",
    "\n",
    "img_paths = [\n",
    "    Path(\"./tempData/cha1\"),\n",
    "    Path(\"./tempData/cha2\"),\n",
    "    Path(\"./tempData/cha3\")\n",
    "]\n",
    "output_path = Path(\"./tempData/merged\")\n",
    "merge_channels(img_paths, output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:53:53.763047Z",
     "start_time": "2023-08-15T08:47:19.766273100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
